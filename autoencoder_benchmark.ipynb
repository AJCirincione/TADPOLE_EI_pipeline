{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-14 20:42:21.431464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-14 20:42:21.653383: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-09-14 20:42:21.653443: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-09-14 20:42:21.704130: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-09-14 20:42:22.835023: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-14 20:42:22.835166: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-14 20:42:22.835182: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras.layers import Dense, Input, Dropout\n",
    "from keras.losses import BinaryCrossentropy\n",
    "from keras import Model\n",
    "from keras.layers.core.dense import regularizers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.utils import shuffle\n",
    "from keras.backend import dropout\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import roc_curve\n",
    "import numpy as np\n",
    "from src.src_utils import sample, fmeasure_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_path = 'data/processed/tadpole_data_imptn_norm.pickle'\n",
    "with open(data_file_path, 'rb') as file:\n",
    "    tadpole_data = pickle.load(file)\n",
    "\n",
    "label_file_path = 'data/processed/tadpole_labels_imptn_norm.pickle'\n",
    "with open(label_file_path, 'rb') as file:\n",
    "    tadpole_labels = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = 'mci_bl'\n",
    "data_split = 'train'\n",
    "concatenated = {}\n",
    "pd.DataFrame()\n",
    "for div in ['train', 'test']:\n",
    "    concatenated[div] = pd.DataFrame()\n",
    "    for mode in tadpole_data[problem][data_split]:\n",
    "        temp = pd.DataFrame(tadpole_data[problem][div][mode])\n",
    "        concatenated[div] = pd.concat([concatenated[div], temp], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ae(layer_size, input_dim,  \n",
    "              loss_fn, optimizer, dropout_rate=0, lr=.001):\n",
    "\n",
    "  input_layer = Input(shape = (input_dim, ))\n",
    "  noise = Dropout(dropout_rate)(input_layer)\n",
    "  encoder = layers.Dense(layer_size, activation = 'relu')\n",
    "  encoded = encoder(noise)\n",
    "  #decoder = Dense(input_dim, activation = 'relu')(encoder)\n",
    "  decoder = DenseTranspose(encoder, activation='relu')(encoded)\n",
    "  autoencoder = Model(inputs = input_layer, outputs = decoder)\n",
    "  autoencoder.compile(loss=loss_fn, \n",
    "                      optimizer=keras.optimizers.Adam(\n",
    "                          learning_rate=lr))\n",
    "\n",
    "  return autoencoder\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "   if epoch < 45:\n",
    "     return lr\n",
    "   else:\n",
    "     return lr * tf.math.exp(-0.1)\n",
    "   \n",
    "def ae_fit_and_predict(ae, input, epochs, batch_size, checkpoint_filepath = '/home/opc/model_checkpoints/model_checkpoints_subfolder/'):\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        save_weights_only=True,\n",
    "        monitor='loss',\n",
    "        mode='min',\n",
    "        save_best_only=True)\n",
    "\n",
    "    callbacks = LearningRateScheduler(scheduler)\n",
    "\n",
    "    stack = ae.fit(input, input, epochs=epochs, batch_size=batch_size, verbose=0, callbacks=[model_checkpoint_callback])\n",
    "    ae.load_weights(checkpoint_filepath)\n",
    "    predict = ae.predict(input, verbose=0)\n",
    "    #del_checkpoints()\n",
    "    return predict\n",
    "\n",
    "def del_checkpoints(checkpoint_filepath = '/home/opc/model_checkpoints/model_checkpoints_subfolder/'):\n",
    "    for filename in os.listdir(checkpoint_filepath):\n",
    "        if ('data' in filename) or ('index' in filename) or ('checkpoint' in filename):\n",
    "            os.remove(checkpoint_filepath + filename)\n",
    "    return \n",
    "\n",
    "def classifier(classifier_input, y, input_dim, epochs, \n",
    "               activation='sigmoid'):\n",
    "\n",
    "  classifier_input_layer = Input(shape = (input_dim, ))\n",
    "  classifier_act = Dense(1, activation=activation)(classifier_input_layer)\n",
    "  classifier = Model(inputs = classifier_input_layer, outputs=classifier_act)\n",
    "  classifier.compile(loss='binary_crossentropy', \n",
    "                     optimizer=keras.optimizers.Adam(learning_rate=0.001), \n",
    "                     metrics=['accuracy'])\n",
    "\n",
    "  return classifier\n",
    "\n",
    "# Adapted from \n",
    "# https://medium.com/@sahoo.puspanjali58/a-beginners-guide-to-build-stacked-autoencoder-and-tying-weights-with-it-9daee61eab2b\n",
    "class DenseTranspose(keras.layers.Layer):\n",
    "  def __init__(self, dense, activation=None, **kwargs):\n",
    "      self.dense = dense\n",
    "      self.activation = keras.activations.get(activation)\n",
    "      super().__init__(**kwargs)\n",
    "  def build(self, batch_input_shape):\n",
    "      self.biases = self.add_weight(name=\"bias\", \n",
    "                  initializer=\"zeros\",shape=[self.dense.input_shape[-1]])\n",
    "      super().build(batch_input_shape)\n",
    "  def call(self, inputs):\n",
    "      z = tf.matmul(inputs, self.dense.weights[0], transpose_b=True)\n",
    "      return self.activation(z + self.biases)  \n",
    "  \n",
    "def ba_max(y_true, y_pred):\n",
    "    one_minus_specs, sensitivity, thresholds = roc_curve(y_true, y_pred)\n",
    "    specificity = 1 - one_minus_specs\n",
    "    balance_accs = (specificity+sensitivity)/2\n",
    "    np_balance_accs = np.array(balance_accs)\n",
    "    max_thres = thresholds[np.argmax(np_balance_accs)]\n",
    "    return max(balance_accs), max_thres\n",
    "\n",
    "def sens_and_spec(y_true, y_pred):\n",
    "    \n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    thresh = ba_max(y_true, y_pred)[1]\n",
    "    y_pred[np.where(y_pred>=thresh)] = 1\n",
    "    y_pred[np.where(y_pred<thresh)] = 0\n",
    "    t_pos = len(np.intersect1d(np.where(y_true==1)[0],np.where(y_pred==1)[0]))\n",
    "    t_neg = len(np.intersect1d(np.where(y_true==0)[0],np.where(y_pred==0)[0]))\n",
    "    f_pos = len(np.intersect1d(np.where(y_true==0)[0],np.where(y_pred==1)[0]))\n",
    "    f_neg = len(np.intersect1d(np.where(y_true==1)[0],np.where(y_pred==0)[0]))\n",
    "    sens = t_pos / (t_pos + f_neg)\n",
    "    spec = t_neg / (t_neg + f_pos)\n",
    "    return sens, spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 15\n",
    "optimizer = 'adam'\n",
    "loss_fn = keras.losses.MeanSquaredError() \n",
    "epochs = 60\n",
    "lr_factor = 0.01\n",
    "\n",
    "x = concatenated['train']\n",
    "x_test = concatenated['test']\n",
    "\n",
    "y = tadpole_labels['mci_bl']['train'].map({'MCI': 0, 'DEM': 1})\n",
    "y = y.reset_index(drop=True)\n",
    "y_test = tadpole_labels['mci_bl']['test'].map({'MCI': 0, 'DEM': 1})\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "#x_train, y = shuffle(x, y)\n",
    "x_train = x\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state = 42)\n",
    "\n",
    "input_size = x_train.shape\n",
    "input_dim = input_size[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- STAGE 0 ----------\n",
      "\n",
      "\n",
      "--- PARAMETER = initial_tuning ---\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/opc/block_vol/TADPOLE_PLATINUM/autoencoder_benchmark.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22416e647265775075625f6d6f72655f6d656d6f7279227d/home/opc/block_vol/TADPOLE_PLATINUM/autoencoder_benchmark.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m autoencoder_2 \u001b[39m=\u001b[39m create_ae(current_params[\u001b[39m'\u001b[39m\u001b[39mhidden_layer2\u001b[39m\u001b[39m'\u001b[39m], dropout_rate\u001b[39m=\u001b[39mcurrent_params[\u001b[39m'\u001b[39m\u001b[39mdropout\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22416e647265775075625f6d6f72655f6d656d6f7279227d/home/opc/block_vol/TADPOLE_PLATINUM/autoencoder_benchmark.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m                         lr\u001b[39m=\u001b[39mcurrent_params[\u001b[39m'\u001b[39m\u001b[39minitial_tuning\u001b[39m\u001b[39m'\u001b[39m], input_dim \u001b[39m=\u001b[39m input_dim, loss_fn \u001b[39m=\u001b[39m loss_fn, optimizer \u001b[39m=\u001b[39m optimizer)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22416e647265775075625f6d6f72655f6d656d6f7279227d/home/opc/block_vol/TADPOLE_PLATINUM/autoencoder_benchmark.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=45'>46</a>\u001b[0m autoencoder_3 \u001b[39m=\u001b[39m create_ae(current_params[\u001b[39m'\u001b[39m\u001b[39mhidden_layer3\u001b[39m\u001b[39m'\u001b[39m], dropout_rate\u001b[39m=\u001b[39mcurrent_params[\u001b[39m'\u001b[39m\u001b[39mdropout\u001b[39m\u001b[39m'\u001b[39m], \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22416e647265775075625f6d6f72655f6d656d6f7279227d/home/opc/block_vol/TADPOLE_PLATINUM/autoencoder_benchmark.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=46'>47</a>\u001b[0m                         lr\u001b[39m=\u001b[39mcurrent_params[\u001b[39m'\u001b[39m\u001b[39minitial_tuning\u001b[39m\u001b[39m'\u001b[39m], input_dim \u001b[39m=\u001b[39m input_dim, loss_fn \u001b[39m=\u001b[39m loss_fn, optimizer \u001b[39m=\u001b[39m optimizer)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22416e647265775075625f6d6f72655f6d656d6f7279227d/home/opc/block_vol/TADPOLE_PLATINUM/autoencoder_benchmark.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=48'>49</a>\u001b[0m ae2_input \u001b[39m=\u001b[39m ae_fit_and_predict(autoencoder_1, x_sample, epochs \u001b[39m=\u001b[39;49m epochs, batch_size\u001b[39m=\u001b[39;49mbatch_size)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22416e647265775075625f6d6f72655f6d656d6f7279227d/home/opc/block_vol/TADPOLE_PLATINUM/autoencoder_benchmark.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=49'>50</a>\u001b[0m ae3_input \u001b[39m=\u001b[39m ae_fit_and_predict(autoencoder_2, ae2_input, epochs \u001b[39m=\u001b[39m epochs, batch_size\u001b[39m=\u001b[39mbatch_size)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22416e647265775075625f6d6f72655f6d656d6f7279227d/home/opc/block_vol/TADPOLE_PLATINUM/autoencoder_benchmark.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=50'>51</a>\u001b[0m classifier_input \u001b[39m=\u001b[39m ae_fit_and_predict(autoencoder_3, ae3_input, epochs \u001b[39m=\u001b[39m epochs, batch_size\u001b[39m=\u001b[39mbatch_size)\n",
      "\u001b[1;32m/home/opc/block_vol/TADPOLE_PLATINUM/autoencoder_benchmark.ipynb Cell 7\u001b[0m in \u001b[0;36mae_fit_and_predict\u001b[0;34m(ae, input, epochs, batch_size, checkpoint_filepath)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22416e647265775075625f6d6f72655f6d656d6f7279227d/home/opc/block_vol/TADPOLE_PLATINUM/autoencoder_benchmark.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m model_checkpoint_callback \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mModelCheckpoint(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22416e647265775075625f6d6f72655f6d656d6f7279227d/home/opc/block_vol/TADPOLE_PLATINUM/autoencoder_benchmark.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m     filepath\u001b[39m=\u001b[39mcheckpoint_filepath,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22416e647265775075625f6d6f72655f6d656d6f7279227d/home/opc/block_vol/TADPOLE_PLATINUM/autoencoder_benchmark.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m     save_weights_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22416e647265775075625f6d6f72655f6d656d6f7279227d/home/opc/block_vol/TADPOLE_PLATINUM/autoencoder_benchmark.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m     monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22416e647265775075625f6d6f72655f6d656d6f7279227d/home/opc/block_vol/TADPOLE_PLATINUM/autoencoder_benchmark.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m     mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmin\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22416e647265775075625f6d6f72655f6d656d6f7279227d/home/opc/block_vol/TADPOLE_PLATINUM/autoencoder_benchmark.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m     save_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22416e647265775075625f6d6f72655f6d656d6f7279227d/home/opc/block_vol/TADPOLE_PLATINUM/autoencoder_benchmark.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m callbacks \u001b[39m=\u001b[39m LearningRateScheduler(scheduler)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22416e647265775075625f6d6f72655f6d656d6f7279227d/home/opc/block_vol/TADPOLE_PLATINUM/autoencoder_benchmark.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m stack \u001b[39m=\u001b[39m ae\u001b[39m.\u001b[39;49mfit(\u001b[39minput\u001b[39;49m, \u001b[39minput\u001b[39;49m, epochs\u001b[39m=\u001b[39;49mepochs, batch_size\u001b[39m=\u001b[39;49mbatch_size, verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[model_checkpoint_callback])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22416e647265775075625f6d6f72655f6d656d6f7279227d/home/opc/block_vol/TADPOLE_PLATINUM/autoencoder_benchmark.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m ae\u001b[39m.\u001b[39mload_weights(checkpoint_filepath)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22416e647265775075625f6d6f72655f6d656d6f7279227d/home/opc/block_vol/TADPOLE_PLATINUM/autoencoder_benchmark.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m predict \u001b[39m=\u001b[39m ae\u001b[39m.\u001b[39mpredict(\u001b[39minput\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1819\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1817\u001b[0m tensor_inputs \u001b[39m=\u001b[39m []\n\u001b[1;32m   1818\u001b[0m variables_used \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m([])\n\u001b[0;32m-> 1819\u001b[0m \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39;49m(args):\n\u001b[1;32m   1820\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(arg, resource_variable_ops\u001b[39m.\u001b[39mBaseResourceVariable):\n\u001b[1;32m   1821\u001b[0m     \u001b[39m# We can pass a variable more than once, and in this case we need to\u001b[39;00m\n\u001b[1;32m   1822\u001b[0m     \u001b[39m# pass its handle only once.\u001b[39;00m\n\u001b[1;32m   1823\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mid\u001b[39m(arg\u001b[39m.\u001b[39mhandle) \u001b[39min\u001b[39;00m variables_used:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_ae_preds = {}\n",
    "all_ae_scores = {}\n",
    "hyperparams = {'initial_tuning': [0.003, 0.001], #'fine_tuning': [.003, .001], \n",
    "               'dropout':[0, 0.2, 0.4, 0.6], 'hidden_layer1': [300, 200], \n",
    "               'hidden_layer2': [150, 100], 'hidden_layer3': [100, 75, 50]}\n",
    "\n",
    "y_pred = np.zeros(y.shape)\n",
    "tuned_hyperparams = {}\n",
    "tuning_stages = range(4)\n",
    "for stage in tuning_stages:\n",
    "    print(f'\\n---------- STAGE {stage} ----------\\n')\n",
    "    tuned_hyperparams[stage] = {}\n",
    "    for param in hyperparams:\n",
    "        print(f'\\n--- PARAMETER = {param} ---\\n')\n",
    "        current_params = {}\n",
    "\n",
    "        for other_params in hyperparams:\n",
    "                if (other_params != param) and (stage == 0):\n",
    "                    if other_params in tuned_hyperparams[stage].keys():\n",
    "                        current_params[other_params] = tuned_hyperparams[stage][other_params]\n",
    "                    else:\n",
    "                        current_params[other_params] = hyperparams[other_params][0]\n",
    "                if (other_params != param) and (stage > 0):\n",
    "                    if other_params in tuned_hyperparams[stage].keys():\n",
    "                        current_params[other_params] = tuned_hyperparams[stage][other_params]\n",
    "                    else:  \n",
    "                        current_params[other_params] = tuned_hyperparams[stage-1][other_params]\n",
    "\n",
    "        sos = []    \n",
    "        for p, vals in enumerate(hyperparams[param]):\n",
    "            current_params[param] = vals\n",
    "            \n",
    "            acc_per_fold = []\n",
    "            fold_no = 1\n",
    "            y_pred = np.zeros(y.shape)\n",
    "\n",
    "            for train, test in kfold.split(x_train, y): \n",
    "\n",
    "                x_sample, y_sample = sample(\n",
    "                        x_train.iloc[train], y.iloc[train], strategy='undersampling', random_state=42)\n",
    "\n",
    "                autoencoder_1 = create_ae(current_params['hidden_layer1'], dropout_rate=current_params['dropout'], \n",
    "                                        lr=current_params['initial_tuning'], input_dim = input_dim, loss_fn = loss_fn, optimizer = optimizer)\n",
    "                autoencoder_2 = create_ae(current_params['hidden_layer2'], dropout_rate=current_params['dropout'],\n",
    "                                        lr=current_params['initial_tuning'], input_dim = input_dim, loss_fn = loss_fn, optimizer = optimizer)\n",
    "                autoencoder_3 = create_ae(current_params['hidden_layer3'], dropout_rate=current_params['dropout'], \n",
    "                                        lr=current_params['initial_tuning'], input_dim = input_dim, loss_fn = loss_fn, optimizer = optimizer)\n",
    "\n",
    "                ae2_input = ae_fit_and_predict(autoencoder_1, x_sample, epochs = epochs, batch_size=batch_size)\n",
    "                ae3_input = ae_fit_and_predict(autoencoder_2, ae2_input, epochs = epochs, batch_size=batch_size)\n",
    "                classifier_input = ae_fit_and_predict(autoencoder_3, ae3_input, epochs = epochs, batch_size=batch_size)\n",
    "                classifier_model = classifier(classifier_input, y_sample, epochs = epochs, input_dim = input_dim)\n",
    "                final_stack = classifier_model.fit(classifier_input, y_sample, epochs=epochs, \n",
    "                                            batch_size=batch_size, verbose=0)\n",
    "                \n",
    "                scores = classifier_model.evaluate(x_train.iloc[test, :], y[test])\n",
    "                y_pred[test] = classifier_model.predict(x_train.iloc[test, :], verbose=0).T[0]\n",
    "                #print(y_pred)\n",
    "\n",
    "                #acc = [scores[1]]\n",
    "                #acc_per_fold += [acc]\n",
    "                #print(f'\\nClass imbalance ratio = {100 * max(1-y[train].sum(), y[train].sum())/len(y[train])}\\n')\n",
    "                fold_no += 1\n",
    "\n",
    "            acc = sum(1 for a,b in zip(y,[round(prediction) for prediction in y_pred]) if a == b) / len(y)\n",
    "            sos.append(acc)\n",
    "        tmp = max(sos)\n",
    "        idx = sos.index(tmp)\n",
    "        tuned_hyperparams[stage][param] = hyperparams[param][idx]\n",
    "        print(hyperparams[param])\n",
    "        print(sos)\n",
    "        print(f'Best val for {param} is {tuned_hyperparams[stage][param]}')\n",
    "        current_params[param]\n",
    "\n",
    "with open(f'AE_params.pkl', 'wb') as f:\n",
    "    pickle.dump(tuned_hyperparams, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5310 - accuracy: 0.7185\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5005 - accuracy: 0.7556\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7761\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5829 - accuracy: 0.6343\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7463\n"
     ]
    }
   ],
   "source": [
    "with open(f'AE_params.pkl', 'rb') as f:\n",
    "    tuned_hyperparams = pickle.load(f)\n",
    "\n",
    "y_pred = np.zeros(y.shape)\n",
    "fold_no = 0\n",
    "for train, test in kfold.split(x_train, y): \n",
    "\n",
    "    x_sample, y_sample = sample(\n",
    "            x_train.iloc[train], y.iloc[train], strategy='undersampling', random_state=42)\n",
    "\n",
    "    autoencoder_1 = create_ae(tuned_hyperparams[3]['hidden_layer1'], dropout_rate=tuned_hyperparams[3]['dropout'], \n",
    "                            lr=tuned_hyperparams[3]['initial_tuning'], input_dim = input_dim, loss_fn = loss_fn, optimizer = optimizer)\n",
    "    autoencoder_2 = create_ae(tuned_hyperparams[3]['hidden_layer2'], dropout_rate=tuned_hyperparams[3]['dropout'],\n",
    "                            lr=tuned_hyperparams[3]['initial_tuning'], input_dim = input_dim, loss_fn = loss_fn, optimizer = optimizer)\n",
    "    autoencoder_3 = create_ae(tuned_hyperparams[3]['hidden_layer3'], dropout_rate=tuned_hyperparams[3]['dropout'], \n",
    "                            lr=tuned_hyperparams[3]['initial_tuning'], input_dim = input_dim, loss_fn = loss_fn, optimizer = optimizer)\n",
    "\n",
    "    ae2_input = ae_fit_and_predict(autoencoder_1, x_sample, epochs = epochs, batch_size=batch_size)\n",
    "    ae3_input = ae_fit_and_predict(autoencoder_2, ae2_input, epochs = epochs, batch_size=batch_size)\n",
    "    classifier_input = ae_fit_and_predict(autoencoder_3, ae3_input, epochs = epochs, batch_size=batch_size)\n",
    "    classifier_model = classifier(classifier_input, y_sample, epochs = epochs, input_dim = input_dim)\n",
    "    final_stack = classifier_model.fit(classifier_input, y_sample, epochs=epochs, \n",
    "                                batch_size=batch_size, verbose=0)\n",
    "    \n",
    "    scores = classifier_model.evaluate(x_train.iloc[test], y.iloc[test])\n",
    "    y_pred[test] = classifier_model.predict(x_train.iloc[test], verbose=0).T[0]\n",
    "    \n",
    "    fold_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV scores:\n",
      "fmax (minority): 0.6688417618270799\n",
      "AUC: 0.8057606434887181\n",
      "f (majority): 0.7222982216142271\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "fmax_dict = fmeasure_score(y, y_pred)\n",
    "fmax = fmax_dict['F']\n",
    "thres = fmax_dict['thres']\n",
    "f = fmeasure_score(y, y_pred, thres=1-thres, pos_label=0)['F']\n",
    "auc = roc_auc_score(y, y_pred)\n",
    "cv_scores = {'Fmax':fmax, 'f (majority)':f, 'AUC':auc, 'thres':thres}\n",
    "print(f'CV scores:\\nfmax (minority): {fmax}\\nAUC: {auc}\\nf (majority): {f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'AE_params.pkl', 'rb') as f:\n",
    "    tuned_hyperparams = pickle.load(f)\n",
    "\n",
    "y_test_pred = np.zeros(y_test.shape)\n",
    "\n",
    "autoencoder_1 = create_ae(tuned_hyperparams[3]['hidden_layer1'], dropout_rate=tuned_hyperparams[3]['dropout'], \n",
    "                        lr=tuned_hyperparams[3]['initial_tuning'], input_dim = input_dim, loss_fn = loss_fn, optimizer = optimizer)\n",
    "autoencoder_2 = create_ae(tuned_hyperparams[3]['hidden_layer2'], dropout_rate=tuned_hyperparams[3]['dropout'],\n",
    "                        lr=tuned_hyperparams[3]['initial_tuning'], input_dim = input_dim, loss_fn = loss_fn, optimizer = optimizer)\n",
    "autoencoder_3 = create_ae(tuned_hyperparams[3]['hidden_layer3'], dropout_rate=tuned_hyperparams[3]['dropout'], \n",
    "                        lr=tuned_hyperparams[3]['initial_tuning'], input_dim = input_dim, loss_fn = loss_fn, optimizer = optimizer)\n",
    "\n",
    "ae2_input = ae_fit_and_predict(autoencoder_1, x_train, epochs = epochs, batch_size=batch_size)\n",
    "ae3_input = ae_fit_and_predict(autoencoder_2, ae2_input, epochs = epochs, batch_size=batch_size)\n",
    "classifier_input = ae_fit_and_predict(autoencoder_3, ae3_input, epochs = epochs, batch_size=batch_size)\n",
    "classifier_model = classifier(classifier_input, y_sample, epochs = epochs, input_dim = input_dim)\n",
    "final_stack = classifier_model.fit(classifier_input, y, epochs=epochs, \n",
    "                            batch_size=batch_size, verbose=0)\n",
    "\n",
    "#scores = classifier_model.evaluate(x_test, y_test)\n",
    "y_test_pred = classifier_model.predict(x_test, verbose=0).T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test scores:\n",
      "f (minority): 0.6356589147286822\n",
      "AUC: 0.7958959899749374\n",
      "f (majority): 0.7751196172248803\n"
     ]
    }
   ],
   "source": [
    "f_dict = fmeasure_score(y_test, y_test_pred, thres = cv_scores['thres'])\n",
    "fminority = f_dict['F']\n",
    "fmajority = fmeasure_score(y_test, y_test_pred, thres=1-cv_scores['thres'], pos_label=0)['F']\n",
    "auc = roc_auc_score(y_test, y_test_pred)\n",
    "test_scores = {'Fmax':fminority, 'f (majority)':fmajority, 'AUC':auc}\n",
    "print(f'Test scores:\\nf (minority): {fminority}\\nAUC: {auc}\\nf (majority): {fmajority}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CV scores: $\\\\$\n",
    "fmax (minority): 0.6688417618270799\n",
    "AUC: 0.8057606434887181\n",
    "f (majority): 0.7222982216142271\n",
    "\n",
    "Test scores: $\\\\$\n",
    "f (minority): 0.6356589147286822\n",
    "AUC: 0.7958959899749374\n",
    "f (majority): 0.7751196172248803"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
